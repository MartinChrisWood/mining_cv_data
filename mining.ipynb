{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Location & Skills/Technologies Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import log\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a word cost dictionary based on Zipf's law, for the english language\n",
    "with open(\"./data/wordninja_words.txt\", \"r\") as f:\n",
    "    words = f.read().split()\n",
    "\n",
    "wordcost = dict((k, log((i+1)*log(len(words)))) for i,k in enumerate(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CV data\n",
    "First, bit of an encoding/formatting problem;  It's not a true json file.  Rather than just load it as text and clean it\n",
    "we fix it by reading in lines, appending the missing formatting and saving back to file (neater)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open(\"./data/Entity Recognition in Resumes.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/ER_data_cleaned.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"[\")\n",
    "    f.write(\",\\n\".join([x for x in lines]))\n",
    "    f.write(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"content\": \"Abhishek Jha\\\\nApplication Development Associate - Accenture\\\\n\\\\nBengaluru, Karnataka - E'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/ER_data_cleaned.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dat = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and clean the cv text to create the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_content(text):\n",
    "    \"\"\" Specific to this data, cleaning up a lot of errant formatting\"\"\"\n",
    "    # Removes errant indeed.com urls\n",
    "    text = \" \".join([x for x in text.split() if \".com\" not in x])\n",
    "    text = \" \".join([x for x in text.split() if \"http\" not in x])\n",
    "    \n",
    "    # Reduce to only alphanumeric\n",
    "    text = re.sub(r\"[^a-zA-Z0-9 \\-+#']\", \"\", text)\n",
    "    \n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [clean_content(example['content']) for example in dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Darshan G Financial Analyst - Oracle Bengaluru Karnataka - Email me on Indeed Hard worker Patience and Good commitment I here by declare that the above-furnished details are true up to my knowledge Place Bangalore Darshan M G Date Signature WORK EXPERIENCE Financial Analyst Oracle - June 2015 to Present Roles and responsibilities  Auditing As per T  E claims  Catalogues Export  import activity  Payment validation  Fall back audits  Manual expenses Inactive employees  Handing queries E-mails  Invoice processing  Handing payment queries  Fringe benefit tax Carrier Achievements  Received Numerous Monthly and Quarterly awards for completing assigned task on time  Received numerous appreciation emails from Vendors for making On Time Payment  Received appreciations emails from Supervisor for knowing End-to-End process and first point of contact person for any escalation  Submitted Innovative ideas to improve the process efficiency and nominated for Internal Award Process associate Accenture - February 2014 to May 2015 Roles  Responsibility  Invoice backlog  Overall hold summary  Payment rejections  Requiting backlog report  PO stuck  Expense hold  Bank details invalid  Schedule payment hold  Work flow  Daily report status  Dash board update EDUCATION MBA in Finance Adhichunchanagiri Institute Of Technology - Chikmagalur Karnataka 2013 B B M in Education I D S G GOVT College - Chikmagalur Karnataka 2010 University  Board SKILLS Excel Less than 1 year MS Excel Less than 1 year Tally Less than 1 year ADDITIONAL INFORMATION Technical Skills Oracle application Rx11  Cloud application Computer skills MS Excel Tally Project Project Title Education loan scheme in credited system Company name Corporation bank Bangalore Team size 1'"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Countries Data\n",
    "Country names from https://datahub.io/core/country-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>AX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name Code\n",
       "0     Afghanistan   AF\n",
       "1   Åland Islands   AX\n",
       "2         Albania   AL\n",
       "3         Algeria   DZ\n",
       "4  American Samoa   AS"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_df = pd.read_csv(\"./data/country_list.csv\")\n",
    "countries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = set(countries_df['Name'].apply(lambda x: x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>subcountry</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>3040051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>3041563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umm al Qaywayn</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Umm al Qaywayn</td>\n",
       "      <td>290594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ras al-Khaimah</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Raʼs al Khaymah</td>\n",
       "      <td>291074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Khawr Fakkān</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Ash Shāriqah</td>\n",
       "      <td>291696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name               country          subcountry  geonameid\n",
       "0      les Escaldes               Andorra  Escaldes-Engordany    3040051\n",
       "1  Andorra la Vella               Andorra    Andorra la Vella    3041563\n",
       "2    Umm al Qaywayn  United Arab Emirates      Umm al Qaywayn     290594\n",
       "3    Ras al-Khaimah  United Arab Emirates     Raʼs al Khaymah     291074\n",
       "4      Khawr Fakkān  United Arab Emirates        Ash Shāriqah     291696"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df = pd.read_csv(\"./data/world-cities.csv\")\n",
    "cities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_lookup = {row['name'].lower(): row['country'].lower() for index, row in cities_df.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Properties of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_countries(tokens, countries=countries):\n",
    "    \"\"\" Expects a list of tokens that may or may not be country names. \"\"\"\n",
    "    return list(countries.intersection(set([x.lower() for x in tokens])))\n",
    "\n",
    "def find_countries_by_city(tokens, cities_lookup=cities_lookup):\n",
    "    \"\"\" Takes a list of tokens that may or may not be city names. \"\"\"\n",
    "    countries = [cities_lookup.get(token.lower(), 0) for token in tokens]\n",
    "    return [country for country in countries if country != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['albania', 'bulgaria']"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_countries([\"Albania\", \"Bulgaria\", \"Dreaming City\", \"Narnia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['united states', 'united kingdom', 'canada', 'mali', 'united states']"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_countries_by_city([\"newport\", \"london\", \"sydney\", \"timbuktu\", \"washington\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(doc):\n",
    "    \"\"\"\n",
    "    Expects SpaCy parsed object. Outputs dict of lists of extracted words by\n",
    "    various categories.\n",
    "    \"\"\"\n",
    "    doc_components = {}\n",
    "    parsed = nlp(doc)\n",
    "    \n",
    "    # Proper nouns extracted, because they tend to be the names of software packages etc\n",
    "    doc_components[\"proper_nouns\"] = [token.text for token in parsed if token.pos_ == 'PROPN']\n",
    "    \n",
    "    # Common nouns extracted, because they tend to be the names of soft skills-related things\n",
    "    doc_components[\"common_nouns\"] = [token.text for token in parsed if token.pos_ == 'NOUN']\n",
    "    \n",
    "    # Dates extracted through SpaCy's Named Entity Recognition\n",
    "    doc_components[\"dates\"] = [X.text for X in parsed.ents if X.label_ == 'DATE']\n",
    "    \n",
    "    doc_components[\"countries\"] = find_countries([X.text for X in parsed])\n",
    "    \n",
    "    if len(doc_components[\"countries\"]) == 0:\n",
    "        doc_components[\"countries\"] = find_countries_by_city([X.text for X in parsed])\n",
    "        \n",
    "    return doc_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases([x.split() for x in corpus], min_count=3, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsed_docs = []\n",
    "for doc in corpus:\n",
    "    parsed_doc = extract_keywords(doc)\n",
    "    parsed_doc['text'] = doc\n",
    "    parsed_doc['phrases'] = phrases[doc.replace(\".\", \"\").split()]\n",
    "    parsed_docs.append(parsed_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Tech Skills\n",
    "### Create a TF-IDF representation of phrases containing Proper Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further clean corpus, only want the 3+ length non-stopwords\n",
    "STOPWORDS = stopwords.words('english')\n",
    "model_corpus = [[word for word in doc['proper_nouns'] + doc['common_nouns'] if (word.lower() not in STOPWORDS) & (len(word) > 2)] for doc in parsed_docs]\n",
    "\n",
    "# Conjoin words that are likely to be phrases\n",
    "phrases = Phrases([x for x in model_corpus], min_count=1, threshold=1)\n",
    "model_corpus = [phrases[doc] for doc in model_corpus]\n",
    "\n",
    "# de-dup - only need each word once\n",
    "model_corpus = [\" \".join(set(doc)) for doc in model_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Database Karnataka_WORK utterances Things System Bengaluru_Karnataka Backend Development_Associate input Vidyalaya Computer Flexible ways Mac opportunity_skills Kendriya Calm Database_Management Present_Role knowledge 12th 10th individual language Chat Machine_Learning EDUCATION Different engineering_college Oracle_PeopleSoft Queries Mathematics INFORMATION_Technical Bvb Polite year_year school_SKILLS Technical_Skills Training Skills_Programming Situations technology year science organization Working Abhishek Tolerant Non user engineering Team_Player Associate_Accenture Linux_Windows Bot Java_ADDITIONAL April_March C++_Java August_June Networks Internet Jha Honest company_growth Application_Development EXPERIENCE_Application Information Hubli_Karnataka bot Email_Bangalore Accenture_November'"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abap</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>accenture</th>\n",
       "      <th>access</th>\n",
       "      <th>account</th>\n",
       "      <th>accounting</th>\n",
       "      <th>accounts</th>\n",
       "      <th>achievement</th>\n",
       "      <th>achievements</th>\n",
       "      <th>...</th>\n",
       "      <th>xml</th>\n",
       "      <th>year</th>\n",
       "      <th>year_information</th>\n",
       "      <th>year_skills</th>\n",
       "      <th>year_year</th>\n",
       "      <th>years</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>years_information</th>\n",
       "      <th>years_year</th>\n",
       "      <th>years_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abap  abilities  ability  accenture  access  account  accounting  accounts  \\\n",
       "0     0          0        0          0       0        0           0         0   \n",
       "1     0          0        1          0       1        0           0         0   \n",
       "2     0          0        0          0       0        0           0         0   \n",
       "3     0          0        1          0       0        0           0         0   \n",
       "4     0          0        0          0       1        0           0         0   \n",
       "\n",
       "   achievement  achievements     ...       xml  year  year_information  \\\n",
       "0            0             0     ...         0     1                 0   \n",
       "1            0             0     ...         1     1                 0   \n",
       "2            0             1     ...         0     0                 0   \n",
       "3            0             0     ...         0     0                 0   \n",
       "4            0             0     ...         0     0                 0   \n",
       "\n",
       "   year_skills  year_year  years  years_experience  years_information  \\\n",
       "0            0          1      0                 0                  0   \n",
       "1            0          1      0                 0                  0   \n",
       "2            0          0      1                 1                  0   \n",
       "3            0          0      0                 1                  1   \n",
       "4            0          1      1                 0                  0   \n",
       "\n",
       "   years_year  years_years  \n",
       "0           0            0  \n",
       "1           0            0  \n",
       "2           0            1  \n",
       "3           0            0  \n",
       "4           1            0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build TF-IDF model with limited vocab size. \n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "vectors = vectorizer.fit_transform(model_corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "# Quick look to check that worked\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset the data to a selection of interest\n",
    "selection = [i for i in range(len(parsed_docs)) if \"python\" in parsed_docs[i]['text'].lower()]\n",
    "#selection = [i for i in range(len(parsed_docs)) if \"united states\" in parsed_docs[i]['countries']]\n",
    "len(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>model</th>\n",
       "      <th>commonality</th>\n",
       "      <th>combined_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>splunk</td>\n",
       "      <td>5</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>jira</td>\n",
       "      <td>7</td>\n",
       "      <td>13.385339</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>automation</td>\n",
       "      <td>10</td>\n",
       "      <td>12.684542</td>\n",
       "      <td>117.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bengaluru_karnataka</td>\n",
       "      <td>9</td>\n",
       "      <td>12.640026</td>\n",
       "      <td>122.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>docker</td>\n",
       "      <td>5</td>\n",
       "      <td>13.914828</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sql</td>\n",
       "      <td>7</td>\n",
       "      <td>12.471330</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>methodologies</td>\n",
       "      <td>4</td>\n",
       "      <td>13.810958</td>\n",
       "      <td>158.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mysql</td>\n",
       "      <td>5</td>\n",
       "      <td>12.895728</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>scripting</td>\n",
       "      <td>6</td>\n",
       "      <td>12.467087</td>\n",
       "      <td>174.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>devops</td>\n",
       "      <td>3</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>infosys</td>\n",
       "      <td>3</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>scm</td>\n",
       "      <td>3</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>crm</td>\n",
       "      <td>3</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>git</td>\n",
       "      <td>3</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>regression</td>\n",
       "      <td>5</td>\n",
       "      <td>12.614527</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>cisco</td>\n",
       "      <td>4</td>\n",
       "      <td>13.018364</td>\n",
       "      <td>189.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>20</td>\n",
       "      <td>11.921965</td>\n",
       "      <td>197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>hyderabad_telangana</td>\n",
       "      <td>3</td>\n",
       "      <td>5005.116628</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>engineer_infosys</td>\n",
       "      <td>3</td>\n",
       "      <td>5004.822998</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>education_btech</td>\n",
       "      <td>3</td>\n",
       "      <td>5004.156252</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>agile</td>\n",
       "      <td>5</td>\n",
       "      <td>12.312680</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>expertise</td>\n",
       "      <td>5</td>\n",
       "      <td>12.242891</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>svn</td>\n",
       "      <td>3</td>\n",
       "      <td>13.369045</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>payroll</td>\n",
       "      <td>3</td>\n",
       "      <td>13.259804</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>intern</td>\n",
       "      <td>3</td>\n",
       "      <td>12.967326</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>optimization</td>\n",
       "      <td>4</td>\n",
       "      <td>12.300091</td>\n",
       "      <td>255.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>jenkins</td>\n",
       "      <td>4</td>\n",
       "      <td>12.159839</td>\n",
       "      <td>271.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>inventory</td>\n",
       "      <td>3</td>\n",
       "      <td>12.585418</td>\n",
       "      <td>276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>implementation</td>\n",
       "      <td>6</td>\n",
       "      <td>11.699153</td>\n",
       "      <td>276.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>responsibilities</td>\n",
       "      <td>6</td>\n",
       "      <td>11.687681</td>\n",
       "      <td>278.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>power_point</td>\n",
       "      <td>0</td>\n",
       "      <td>8.330920</td>\n",
       "      <td>1737.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>end_user</td>\n",
       "      <td>0</td>\n",
       "      <td>8.253748</td>\n",
       "      <td>1742.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>party</td>\n",
       "      <td>0</td>\n",
       "      <td>8.219180</td>\n",
       "      <td>1747.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>home</td>\n",
       "      <td>0</td>\n",
       "      <td>8.216010</td>\n",
       "      <td>1748.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>project_team</td>\n",
       "      <td>0</td>\n",
       "      <td>8.188622</td>\n",
       "      <td>1749.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>capital</td>\n",
       "      <td>0</td>\n",
       "      <td>8.129864</td>\n",
       "      <td>1755.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>help</td>\n",
       "      <td>0</td>\n",
       "      <td>8.101792</td>\n",
       "      <td>1756.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>support_team</td>\n",
       "      <td>0</td>\n",
       "      <td>8.059922</td>\n",
       "      <td>1760.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>page</td>\n",
       "      <td>0</td>\n",
       "      <td>8.054424</td>\n",
       "      <td>1761.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>april</td>\n",
       "      <td>0</td>\n",
       "      <td>8.046934</td>\n",
       "      <td>1762.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>team_lead</td>\n",
       "      <td>0</td>\n",
       "      <td>8.043160</td>\n",
       "      <td>1763.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>project_name</td>\n",
       "      <td>0</td>\n",
       "      <td>8.041848</td>\n",
       "      <td>1764.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>times</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000772</td>\n",
       "      <td>1766.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>form</td>\n",
       "      <td>0</td>\n",
       "      <td>7.980890</td>\n",
       "      <td>1768.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>book</td>\n",
       "      <td>0</td>\n",
       "      <td>7.935708</td>\n",
       "      <td>1771.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>may_present</td>\n",
       "      <td>0</td>\n",
       "      <td>7.885839</td>\n",
       "      <td>1775.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>high_school</td>\n",
       "      <td>0</td>\n",
       "      <td>7.870519</td>\n",
       "      <td>1777.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>end</td>\n",
       "      <td>0</td>\n",
       "      <td>7.866115</td>\n",
       "      <td>1779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>word</td>\n",
       "      <td>0</td>\n",
       "      <td>7.847933</td>\n",
       "      <td>1781.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>countries</td>\n",
       "      <td>0</td>\n",
       "      <td>7.838716</td>\n",
       "      <td>1784.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>day_day</td>\n",
       "      <td>0</td>\n",
       "      <td>7.736437</td>\n",
       "      <td>1789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>government</td>\n",
       "      <td>0</td>\n",
       "      <td>7.628223</td>\n",
       "      <td>1794.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>place</td>\n",
       "      <td>0</td>\n",
       "      <td>7.610932</td>\n",
       "      <td>1795.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>way</td>\n",
       "      <td>0</td>\n",
       "      <td>7.440171</td>\n",
       "      <td>1797.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>number</td>\n",
       "      <td>0</td>\n",
       "      <td>7.330972</td>\n",
       "      <td>1800.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>player</td>\n",
       "      <td>0</td>\n",
       "      <td>7.234122</td>\n",
       "      <td>1802.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>team_player</td>\n",
       "      <td>0</td>\n",
       "      <td>7.216879</td>\n",
       "      <td>1804.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>national</td>\n",
       "      <td>0</td>\n",
       "      <td>7.181936</td>\n",
       "      <td>1808.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>name</td>\n",
       "      <td>0</td>\n",
       "      <td>6.906089</td>\n",
       "      <td>1815.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>people</td>\n",
       "      <td>0</td>\n",
       "      <td>5.959945</td>\n",
       "      <td>1821.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    word  model  commonality  combined_rank\n",
       "78                splunk      5  9999.000000           88.0\n",
       "25                  jira      7    13.385339          102.0\n",
       "10            automation     10    12.684542          117.5\n",
       "11   bengaluru_karnataka      9    12.640026          122.5\n",
       "74                docker      5    13.914828          124.0\n",
       "28                   sql      7    12.471330          157.0\n",
       "105        methodologies      4    13.810958          158.5\n",
       "62                 mysql      5    12.895728          160.0\n",
       "50             scripting      6    12.467087          174.5\n",
       "186               devops      3  9999.000000          180.0\n",
       "157              infosys      3  9999.000000          180.0\n",
       "146                  scm      3  9999.000000          180.0\n",
       "140                  crm      3  9999.000000          180.0\n",
       "122                  git      3  9999.000000          180.0\n",
       "66            regression      5    12.614527          180.0\n",
       "82                 cisco      4    13.018364          189.5\n",
       "0                 python     20    11.921965          197.0\n",
       "142  hyderabad_telangana      3  5005.116628          199.0\n",
       "174     engineer_infosys      3  5004.822998          203.0\n",
       "183      education_btech      3  5004.156252          205.0\n",
       "75                 agile      5    12.312680          217.0\n",
       "71             expertise      5    12.242891          229.0\n",
       "193                  svn      3    13.369045          233.0\n",
       "192              payroll      3    13.259804          238.0\n",
       "139               intern      3    12.967326          250.0\n",
       "89          optimization      4    12.300091          255.5\n",
       "120              jenkins      4    12.159839          271.5\n",
       "143            inventory      3    12.585418          276.0\n",
       "40        implementation      6    11.699153          276.5\n",
       "51      responsibilities      6    11.687681          278.5\n",
       "..                   ...    ...          ...            ...\n",
       "793          power_point      0     8.330920         1737.5\n",
       "907             end_user      0     8.253748         1742.5\n",
       "776                party      0     8.219180         1747.5\n",
       "879                 home      0     8.216010         1748.5\n",
       "737         project_team      0     8.188622         1749.5\n",
       "726              capital      0     8.129864         1755.5\n",
       "876                 help      0     8.101792         1756.5\n",
       "848         support_team      0     8.059922         1760.5\n",
       "772                 page      0     8.054424         1761.5\n",
       "705                april      0     8.046934         1762.5\n",
       "857            team_lead      0     8.043160         1763.5\n",
       "735         project_name      0     8.041848         1764.5\n",
       "863                times      0     8.000772         1766.5\n",
       "929                 form      0     7.980890         1768.5\n",
       "713                 book      0     7.935708         1771.5\n",
       "944          may_present      0     7.885839         1775.5\n",
       "878          high_school      0     7.870519         1777.5\n",
       "906                  end      0     7.866115         1779.0\n",
       "826                 word      0     7.847933         1781.5\n",
       "675            countries      0     7.838716         1784.5\n",
       "680              day_day      0     7.736437         1789.0\n",
       "869           government      0     7.628223         1794.5\n",
       "784                place      0     7.610932         1795.5\n",
       "823                  way      0     7.440171         1797.5\n",
       "962               number      0     7.330972         1800.5\n",
       "786               player      0     7.234122         1802.5\n",
       "858          team_player      0     7.216879         1804.5\n",
       "958             national      0     7.181936         1808.5\n",
       "957                 name      0     6.906089         1815.5\n",
       "779               people      0     5.959945         1821.5\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum the TF-IDF scores by word, pivot\n",
    "summed_scores = df.iloc[selection].sum(axis=0).sort_values(ascending=False)\n",
    "output = pd.DataFrame({\"word\":summed_scores.index, \"model\":summed_scores.values})\n",
    "\n",
    "# Calculate the commonality of each word (or both, for zipf's law) with Zipf's law, unrecognised gets 9999\n",
    "output['commonality'] = output['word'].apply(lambda x: sum([wordcost.get(y.lower(), 9999) for y in x.split(\"_\")]) / len(x.split(\"_\")))\n",
    "\n",
    "# Rank the importance of each word for this group of documents according to TF-IDF and rarity.  Higher == Better!\n",
    "output['combined_rank'] = output['commonality'].rank(ascending=False) + output['model'].rank(ascending=False)\n",
    "output.sort_values('combined_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
